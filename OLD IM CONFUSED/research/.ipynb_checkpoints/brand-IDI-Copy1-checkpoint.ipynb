{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing Word Frequency for Brand Perception Interviews\n",
    "amongst key stakeholders NYCAASC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk import word_tokenize, pos_tag\n",
    "import math\n",
    "import string\n",
    "from collections import Counter\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nltk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-60474dd24e0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# only need to run once\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'nltk' is not defined"
     ]
    }
   ],
   "source": [
    "# only need to run once\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/chuamelia/Downloads/Brand_IDI_Qual.tsv\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at Structure of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>a_position_toNYCAASC</th>\n",
       "      <th>b_position_toNYCAASC</th>\n",
       "      <th>embody_Mission</th>\n",
       "      <th>future_Direction</th>\n",
       "      <th>first_Time</th>\n",
       "      <th>logo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Umm, I guess I do a lot of the upper level man...</td>\n",
       "      <td>I see it as, well I see my role as kinda givin...</td>\n",
       "      <td>I think that a good, I talked about this earli...</td>\n",
       "      <td>I wanna see it reaching more people and being ...</td>\n",
       "      <td>I guess, NYCAASC is kind of divided between th...</td>\n",
       "      <td>The spelling is a little confusing because of ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                               a_position_toNYCAASC  \\\n",
       "0   1  Umm, I guess I do a lot of the upper level man...   \n",
       "\n",
       "                                b_position_toNYCAASC  \\\n",
       "0  I see it as, well I see my role as kinda givin...   \n",
       "\n",
       "                                      embody_Mission  \\\n",
       "0  I think that a good, I talked about this earli...   \n",
       "\n",
       "                                    future_Direction  \\\n",
       "0  I wanna see it reaching more people and being ...   \n",
       "\n",
       "                                          first_Time  \\\n",
       "0  I guess, NYCAASC is kind of divided between th...   \n",
       "\n",
       "                                                logo  \n",
       "0  The spelling is a little confusing because of ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Functions for Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Table of Word Types][Table of Word Type]\n",
    "[Table of Word Type]: http://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Write function to append all tokens to one list.\n",
    "def stuff_tokenizer(column, list):\n",
    "    discard = ['IN', ',','.','TO', 'DT', 'PRP', 'CC', 'are', 'is', 'um', u'it\\u2019s', 'PRP$']\n",
    "    end_num = len(column)\n",
    "    temp = []\n",
    "    for i in range(end_num): #append to one list\n",
    "        temp.extend(word_tokenize(column[i].decode('utf-8')))\n",
    "    temp2 = pos_tag(temp) #tag words\n",
    "    for i in temp2: #discard prepositions, articles, etc.\n",
    "        if i[1] not in discard and i[0] not in discard: \n",
    "            list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#add decode('utf-8') bc \"\\xe2\\x80\\x99\" interprtation\n",
    "#ascii' codec can't decode byte\n",
    "#example: df['first_Time'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create empty lists for stuffing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q1a = []\n",
    "q1b = []\n",
    "q2 = []\n",
    "q3 = []\n",
    "q4 = []\n",
    "q5 = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stuff Away!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stuff_tokenizer(df['a_position_toNYCAASC'],q1a)\n",
    "stuff_tokenizer(df['b_position_toNYCAASC'],q1b)\n",
    "stuff_tokenizer(df['embody_Mission'],q2)\n",
    "stuff_tokenizer(df['future_Direction'],q3)\n",
    "stuff_tokenizer(df['first_Time'],q4)\n",
    "stuff_tokenizer(df['logo'],q5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if stuffing worked..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print q1a[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = [q1a,q1b,q2,q3,q4,q5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((u'just', 'RB'), 15), ((u'what', 'WP'), 13), ((u'do', 'VBP'), 12), ((u'also', 'RB'), 11), ((u'sort', 'NN'), 9)]\n",
      "[((u'people', 'NNS'), 16), ((u'conference', 'NN'), 13), ((u'think', 'VBP'), 12), ((u'know', 'VBP'), 12), ((u'that', 'WDT'), 11)]\n",
      "[((u'so', 'RB'), 19), ((u'really', 'RB'), 17), ((u'was', 'VBD'), 16), ((u'just', 'RB'), 14), ((u'Asian', 'JJ'), 14)]\n",
      "[((u'be', 'VB'), 33), ((u'think', 'VBP'), 32), ((u'know', 'VBP'), 25), ((u'people', 'NNS'), 24), ((u'want', 'VBP'), 22)]\n",
      "[((u'people', 'NNS'), 15), ((u'be', 'VB'), 14), ((u'know', 'VBP'), 13), ((u'want', 'VBP'), 13), ((u'that', 'WDT'), 12)]\n",
      "[((u'think', 'VBP'), 20), ((u'don\\u2019t', 'VBP'), 13), ((u'be', 'VB'), 13), ((u'just', 'RB'), 12), ((u'not', 'RB'), 11)]\n"
     ]
    }
   ],
   "source": [
    "for i in dataset:\n",
    "    common = Counter(i)\n",
    "    print common.most_common(5)\n",
    "# Need to remove prepositions\n",
    "# How can we control for one person repeating the same word?\n",
    "# select distinct words: my_list = list(set(my_list))\n",
    "# compare word counts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((u'people', 'NNS'), 15),\n",
       " ((u'be', 'VB'), 14),\n",
       " ((u'know', 'VBP'), 13),\n",
       " ((u'want', 'VBP'), 13),\n",
       " ((u'that', 'WDT'), 12),\n",
       " ((u'think', 'VBP'), 12),\n",
       " ((u'issues', 'NNS'), 12),\n",
       " ((u'really', 'RB'), 12),\n",
       " ((u'just', 'RB'), 11),\n",
       " ((u'thing', 'NN'), 11),\n",
       " ((u'lot', 'NN'), 11),\n",
       " ((u'also', 'RB'), 11),\n",
       " ((u'who', 'WP'), 9),\n",
       " ((u'not', 'RB'), 9),\n",
       " ((u'don\\u2019t', 'VBP'), 8),\n",
       " ((u'Um', 'NNP'), 8),\n",
       " ((u'right', 'RB'), 8),\n",
       " ((u'NYCAASC', 'NNP'), 7),\n",
       " ((u'think', 'VB'), 7),\n",
       " ((u'have', 'VBP'), 7),\n",
       " ((u'sort', 'NN'), 6),\n",
       " ((u'do', 'VBP'), 6),\n",
       " ((u'do', 'VB'), 6),\n",
       " ((u'can', 'MD'), 6),\n",
       " ((u'kind', 'NN'), 6),\n",
       " ((u'talk', 'VB'), 6),\n",
       " ((u'come', 'VB'), 6),\n",
       " ((u'one', 'CD'), 6),\n",
       " ((u'things', 'NNS'), 6),\n",
       " ((u'being', 'VBG'), 6),\n",
       " ((u'so', 'RB'), 6),\n",
       " ((u'guess', 'VBP'), 5),\n",
       " ((u'how', 'WRB'), 5),\n",
       " ((u'would', 'MD'), 5),\n",
       " ((u'important', 'JJ'), 5),\n",
       " ((u'feel', 'VBP'), 5),\n",
       " ((u'stories', 'NNS'), 5),\n",
       " ((u'may', 'MD'), 5),\n",
       " ((u'know', 'VB'), 5),\n",
       " ((u'conference', 'NN'), 5),\n",
       " ((u'other', 'JJ'), 5),\n",
       " ((u'was', 'VBD'), 5),\n",
       " ((u'very', 'RB'), 5),\n",
       " ((u'we\\u2019re', 'NN'), 5),\n",
       " ((u'what', 'WP'), 5),\n",
       " ((u'able', 'JJ'), 5),\n",
       " ((u'involved', 'VBN'), 4),\n",
       " ((u'community', 'NN'), 4),\n",
       " ((u'exposure', 'NN'), 4),\n",
       " ((u'space', 'NN'), 4),\n",
       " ((u'friends', 'NNS'), 4),\n",
       " ((u'I\\u2019ve', 'NNP'), 4),\n",
       " ((u'said', 'VBD'), 4),\n",
       " ((u'Asian', 'JJ'), 4),\n",
       " ((u'then', 'RB'), 4),\n",
       " ((u'why', 'WRB'), 4),\n",
       " ((u'hear', 'VB'), 4),\n",
       " ((u'first', 'JJ'), 4),\n",
       " ((u'taking', 'VBG'), 3),\n",
       " ((u'care', 'VBP'), 3),\n",
       " ((u'more', 'JJR'), 3),\n",
       " ((u'say', 'VBP'), 3),\n",
       " ((u'fosters', 'NNS'), 3),\n",
       " ((u'deal', 'NN'), 3),\n",
       " ((u'students', 'NNS'), 3),\n",
       " ((u'get', 'VB'), 3),\n",
       " ((u'there', 'EX'), 3),\n",
       " ((u'always', 'RB'), 3),\n",
       " ((u'So', 'RB'), 3),\n",
       " ((u'someone', 'NN'), 3),\n",
       " ((u'interested', 'JJ'), 3),\n",
       " ((u'history', 'NN'), 3),\n",
       " ((u'big', 'JJ'), 3),\n",
       " ((u'should', 'MD'), 3),\n",
       " ((u'definitely', 'RB'), 3),\n",
       " ((u'like', 'VBP'), 3),\n",
       " ((u'personal', 'JJ'), 3),\n",
       " ((u'tell', 'VBP'), 3),\n",
       " ((u'out', 'RP'), 3),\n",
       " ((u'student', 'NN'), 3),\n",
       " ((u'way', 'NN'), 3),\n",
       " ((u'place', 'NN'), 3),\n",
       " ((u'when', 'WRB'), 3),\n",
       " ((u'course', 'NN'), 2),\n",
       " ((u'stuff', 'NN'), 2),\n",
       " ((u'How', 'NNP'), 2),\n",
       " ((u'vulnerability', 'NN'), 2),\n",
       " ((u'American', 'NNP'), 2),\n",
       " ((u'let', 'VB'), 2),\n",
       " ((u'regardless', 'RB'), 2),\n",
       " ((u'biggest', 'JJS'), 2),\n",
       " ((u'dialogue', 'NN'), 2),\n",
       " ((u'more', 'RBR'), 2),\n",
       " ((u'like', 'JJ'), 2),\n",
       " ((u'person', 'NN'), 2),\n",
       " ((u'talking', 'VBG'), 2),\n",
       " ((u'isn\\u2019t', 'JJ'), 2),\n",
       " ((u'hopefully', 'RB'), 2),\n",
       " ((u'ask', 'VB'), 2),\n",
       " ((u'go', 'VBP'), 2),\n",
       " ((u'saying', 'VBG'), 2),\n",
       " ((u'group', 'NN'), 2),\n",
       " ((u'here', 'RB'), 2),\n",
       " ((u'obviously', 'RB'), 2),\n",
       " ((u'make', 'VB'), 2),\n",
       " ((u'studies', 'NNS'), 2),\n",
       " ((u'I\\u2019ll', 'NNP'), 2),\n",
       " ((u'anything', 'NN'), 2),\n",
       " ((u'part', 'NN'), 2),\n",
       " ((u'ethnic', 'JJ'), 2),\n",
       " ((u'growth', 'NN'), 2),\n",
       " ((u'fun', 'JJ'), 2),\n",
       " ((u'feel', 'VB'), 2),\n",
       " ((u'world', 'NN'), 2),\n",
       " ((u'trying', 'VBG'), 2),\n",
       " ((u'college', 'NN'), 2),\n",
       " ((u'comfortable', 'JJ'), 2),\n",
       " ((u'forth', 'NN'), 2),\n",
       " ((u'there\\u2019s', 'NN'), 2),\n",
       " ((u'going', 'VBG'), 2),\n",
       " ((u'larger', 'JJR'), 2),\n",
       " ((u'have', 'VB'), 2),\n",
       " ((u'organization', 'NN'), 2),\n",
       " ((u'that\\u2019s', 'JJ'), 2),\n",
       " ((u'discussion', 'NN'), 2),\n",
       " ((u'accessible', 'JJ'), 2),\n",
       " ((u'learn', 'VB'), 2),\n",
       " ((u'whatever', 'WDT'), 2),\n",
       " ((u'did', 'VBD'), 2),\n",
       " ((u'AAPI', 'NNP'), 2),\n",
       " ((u'initial', 'JJ'), 2),\n",
       " ((u'create', 'VB'), 2),\n",
       " ((u'joined', 'VBD'), 2),\n",
       " ((u'which', 'WDT'), 2),\n",
       " ((u'again', 'RB'), 2),\n",
       " ((u'something', 'NN'), 2),\n",
       " ((u'enough', 'RB'), 2),\n",
       " ((u'putting', 'VBG'), 2),\n",
       " ((u'creating', 'VBG'), 2),\n",
       " ((u'conversations', 'NNS'), 2),\n",
       " ((u'helps', 'VBZ'), 1),\n",
       " ((u'actually', 'RB'), 1),\n",
       " ((u'debate', 'VBP'), 1),\n",
       " ((u'creation', 'NN'), 1),\n",
       " ((u'together', 'RB'), 1),\n",
       " ((u'etc', 'NN'), 1),\n",
       " ((u'little', 'JJ'), 1),\n",
       " ((u'term', 'NN'), 1),\n",
       " ((u'already', 'RB'), 1),\n",
       " ((u'talked', 'VBN'), 1),\n",
       " ((u'put', 'VB'), 1),\n",
       " ((u'representation', 'NN'), 1),\n",
       " ((u'pass', 'VB'), 1),\n",
       " ((u'air', 'NN'), 1),\n",
       " ((u'kinda', 'FW'), 1),\n",
       " ((u'aware', 'JJ'), 1),\n",
       " ((u'fundraising', 'VBG'), 1),\n",
       " ((u'passionate', 'NN'), 1),\n",
       " ((u'model', 'NN'), 1),\n",
       " ((u'we\\u2019re', 'VBP'), 1),\n",
       " ((u'ARE', 'VBP'), 1),\n",
       " ((u'significant', 'JJ'), 1),\n",
       " ((u'will', 'MD'), 1),\n",
       " ((u'oh', 'NNS'), 1),\n",
       " ((u'up', 'RP'), 1),\n",
       " ((u'impact', 'VB'), 1),\n",
       " ((u'uh', 'EX'), 1),\n",
       " ((u'divided', 'VBN'), 1),\n",
       " ((u'yeah', 'NN'), 1),\n",
       " ((u'that\\u2019s', 'NNS'), 1),\n",
       " ((u'now', 'RB'), 1),\n",
       " ((u'told', 'VBD'), 1),\n",
       " ((u'planning', 'VBG'), 1),\n",
       " ((u'like', 'VB'), 1),\n",
       " ((u'giving', 'VBG'), 1),\n",
       " ((u'address', 'VBP'), 1),\n",
       " ((u'good', 'JJ'), 1),\n",
       " ((u'Saturday', 'NNP'), 1),\n",
       " ((u'I\\u2019m', 'NNP'), 1),\n",
       " ((u'hum', 'NN'), 1),\n",
       " ((u'regardless', 'NN'), 1),\n",
       " ((u'experiences', 'NNS'), 1),\n",
       " ((u'middle', 'JJ'), 1),\n",
       " ((u'nothing', 'NN'), 1),\n",
       " ((u'brand', 'NN'), 1),\n",
       " ((u'get', 'VBP'), 1),\n",
       " ((u'were', 'VBD'), 1),\n",
       " ((u'POC', 'NNP'), 1),\n",
       " ((u'started', 'VBD'), 1),\n",
       " ((u'see', 'VB'), 1),\n",
       " ((u'open', 'JJ'), 1),\n",
       " ((u'usually', 'RB'), 1),\n",
       " ((u'ongoing', 'VBG'), 1),\n",
       " ((u'professional', 'JJ'), 1),\n",
       " ((u'etc', 'VBP'), 1),\n",
       " ((u'Let\\u2019s', 'NNP'), 1),\n",
       " ((u'hard', 'JJ'), 1),\n",
       " ((u'past', 'JJ'), 1),\n",
       " ((u'values', 'NNS'), 1),\n",
       " ((u'programs', 'NNS'), 1),\n",
       " ((u'voice', 'VB'), 1),\n",
       " ((u'bit', 'NN'), 1),\n",
       " ((u'tomorrow', 'NN'), 1),\n",
       " ((u'oh', 'UH'), 1),\n",
       " ((u'force', 'NN'), 1),\n",
       " ((u'impacting', 'VBG'), 1),\n",
       " ((u'enough', 'JJ'), 1),\n",
       " ((u'focus', 'VBP'), 1),\n",
       " ((u'hope', 'VBP'), 1),\n",
       " ((u'city-wide', 'JJ'), 1),\n",
       " ((u'everything', 'NN'), 1),\n",
       " ((u'own', 'JJ'), 1),\n",
       " ((u'better', 'JJR'), 1),\n",
       " ((u'NYU', 'NNP'), 1),\n",
       " ((u'doesn\\u2019t', 'NN'), 1),\n",
       " ((u'mine', 'NN'), 1),\n",
       " ((u'care', 'VB'), 1),\n",
       " ((u'meet', 'VB'), 1),\n",
       " ((u'back', 'RB'), 1),\n",
       " ((u'different', 'JJ'), 1),\n",
       " ((u'NYCAASC\\u2019s', 'NNP'), 1),\n",
       " ((u'facilitate', 'NN'), 1),\n",
       " ((u'event', 'NN'), 1),\n",
       " ((u'school', 'NN'), 1),\n",
       " ((u'uh', 'JJ'), 1),\n",
       " ((u'openness', 'NN'), 1),\n",
       " ((u'there\\u2019s', 'VBP'), 1),\n",
       " ((u'come', 'VBP'), 1),\n",
       " ((u'many', 'JJ'), 1),\n",
       " ((u'judgments', 'NNS'), 1),\n",
       " ((u'bigger', 'JJR'), 1),\n",
       " ((u'daily', 'JJ'), 1),\n",
       " ((u'heads', 'NNS'), 1),\n",
       " ((u'somebody', 'NN'), 1),\n",
       " ((u'deeply', 'RB'), 1),\n",
       " ((u'consider', 'VBP'), 1),\n",
       " ((u'become', 'VB'), 1),\n",
       " ((u'talk', 'VBP'), 1),\n",
       " ((u'well', 'RB'), 1),\n",
       " ((u'involved', 'VBD'), 1),\n",
       " ((u'scope', 'NN'), 1),\n",
       " ((u'complex', 'JJ'), 1),\n",
       " ((u'ever', 'RB'), 1),\n",
       " ((u'takes', 'VBZ'), 1),\n",
       " ((u'could', 'MD'), 1),\n",
       " ((u'heard', 'JJR'), 1),\n",
       " ((u'That\\u2019s', 'NNP'), 1),\n",
       " ((u'almost', 'RB'), 1),\n",
       " ((u'hundreds', 'NNS'), 1),\n",
       " ((u'impressive', 'JJ'), 1),\n",
       " ((u'fund', 'VB'), 1),\n",
       " ((u'impact', 'NN'), 1),\n",
       " ((u'City', 'NNP'), 1),\n",
       " ((u'possible', 'JJ'), 1),\n",
       " ((u'hmm', 'NN'), 1),\n",
       " ((u'relates', 'VBZ'), 1),\n",
       " ((u'means', 'VBZ'), 1),\n",
       " ((u'well-versed', 'JJ'), 1),\n",
       " ((u'\\u201d', 'VB'), 1),\n",
       " ((u'having', 'VBG'), 1),\n",
       " ((u'pushing', 'VBG'), 1),\n",
       " ((u'It\\u2019s', 'VB'), 1),\n",
       " ((u'voice', 'NN'), 1),\n",
       " ((u'week', 'NN'), 1),\n",
       " ((u'Ideally', 'RB'), 1),\n",
       " ((u'members', 'NNS'), 1),\n",
       " ((u'break', 'NN'), 1),\n",
       " ((u'once', 'RB'), 1),\n",
       " ((u'comes', 'VBZ'), 1),\n",
       " ((u'committees', 'NNS'), 1),\n",
       " ((u'fully', 'RB'), 1),\n",
       " ((u'realize', 'VB'), 1),\n",
       " ((u'notice', 'JJ'), 1),\n",
       " ((u'mean', 'VBP'), 1),\n",
       " ((u'uh', 'NN'), 1),\n",
       " ((u'connecting', 'VBG'), 1),\n",
       " ((u'talk', 'NN'), 1),\n",
       " ((u'topic', 'NN'), 1),\n",
       " ((u'assume', 'VB'), 1),\n",
       " ((u'fundraising', 'NN'), 1),\n",
       " ((u'face', 'NN'), 1),\n",
       " ((u'NOT', 'JJ'), 1),\n",
       " ((u'time', 'NN'), 1),\n",
       " ((u'sort', 'VB'), 1),\n",
       " ((u'intercollegiate', 'NN'), 1),\n",
       " ((u'Yeah', 'UH'), 1),\n",
       " ((u'faces', 'VBZ'), 1),\n",
       " ((u'legitimate', 'JJ'), 1),\n",
       " ((u'powerful', 'JJ'), 1),\n",
       " ((u'we\\u2019re', 'RB'), 1),\n",
       " ((u'mine', 'VBP'), 1),\n",
       " ((u'immediately', 'RB'), 1),\n",
       " ((u'platform', 'NN'), 1),\n",
       " ((u'50', 'CD'), 1),\n",
       " ((u'pitching', 'VBG'), 1),\n",
       " ((u'yeah', 'UH'), 1),\n",
       " ((u'lack', 'NN'), 1),\n",
       " ((u'whenever', 'WRB'), 1),\n",
       " ((u'necessarily', 'RB'), 1),\n",
       " ((u'there', 'RB'), 1),\n",
       " ((u'Basically', 'NNP'), 1),\n",
       " ((u'i', 'JJ'), 1),\n",
       " ((u'limited', 'VBN'), 1),\n",
       " ((u'getting', 'VBG'), 1),\n",
       " ((u'year', 'NN'), 1),\n",
       " ((u'looks', 'VBZ'), 1),\n",
       " ((u'back', 'NN'), 1),\n",
       " ((u'great', 'JJ'), 1),\n",
       " ((u'teller', 'NN'), 1),\n",
       " ((u'day', 'NN'), 1),\n",
       " ((u'story', 'NN'), 1),\n",
       " ((u'everyone\\u2019s', 'NN'), 1),\n",
       " ((u'Intimacy', 'NNP'), 1),\n",
       " ((u'That\\u2019s', 'VB'), 1),\n",
       " ((u'Right', 'NNP'), 1),\n",
       " ((u'show', 'VBP'), 1),\n",
       " ((u'especially', 'RB'), 1),\n",
       " ((u'oh', 'JJ'), 1),\n",
       " ((u'Passing', 'NN'), 1),\n",
       " ((u'encourages', 'VBZ'), 1),\n",
       " ((u'meaningful', 'JJ'), 1),\n",
       " ((u'sacred', 'VBD'), 1),\n",
       " ((u'affirming', 'VBG'), 1),\n",
       " ((u'main', 'JJ'), 1),\n",
       " ((u'8', 'CD'), 1),\n",
       " ((u'large', 'JJ'), 1),\n",
       " ((u'hand', 'NN'), 1),\n",
       " ((u'go', 'VB'), 1),\n",
       " ((u'right', 'NN'), 1),\n",
       " ((u'dependent', 'NN'), 1),\n",
       " ((u'serious', 'JJ'), 1),\n",
       " ((u'minority', 'NN'), 1),\n",
       " ((u'question', 'NN'), 1),\n",
       " ((u'York', 'NNP'), 1),\n",
       " ((u'That', 'WDT'), 1),\n",
       " ((u'table', 'NN'), 1),\n",
       " ((u'difficult', 'JJ'), 1),\n",
       " ((u'discuss', 'VB'), 1),\n",
       " ((u'regular', 'JJ'), 1),\n",
       " ((u'Right', 'RB'), 1),\n",
       " ((u'New', 'NNP'), 1),\n",
       " ((u'exposed', 'VBN'), 1),\n",
       " ((u'\\u201cShould', 'VBP'), 1),\n",
       " ((u'association', 'NN'), 1),\n",
       " ((u'issue', 'NN'), 1),\n",
       " ((u'needs', 'VBZ'), 1),\n",
       " ((u'words', 'NNS'), 1),\n",
       " ((u'know', 'JJ'), 1),\n",
       " ((u'Uhm', 'NNP'), 1),\n",
       " ((u'conscious', 'JJ'), 1),\n",
       " ((u'I\\u2019d', 'NNP'), 1),\n",
       " ((u'same', 'JJ'), 1),\n",
       " ((u'that\\u2019s', 'EX'), 1),\n",
       " ((u'beliefs', 'NN'), 1),\n",
       " ((u'drum', 'NN'), 1),\n",
       " ((u'too', 'RB'), 1),\n",
       " ((u'later', 'RB'), 1),\n",
       " ((u'most', 'RBS'), 1),\n",
       " ((u'instances', 'NNS'), 1),\n",
       " ((u'nycaasc', 'NN'), 1),\n",
       " ((u'individual', 'JJ'), 1),\n",
       " ((u'intimacy', 'NN'), 1),\n",
       " ((u'power', 'NN'), 1),\n",
       " ((u'there\\u2019s', 'VBZ'), 1),\n",
       " ((u'thewhole', 'JJ'), 1),\n",
       " ((u'we\\u2019re', 'JJ'), 1),\n",
       " ((u'Should', 'MD'), 1),\n",
       " ((u'others', 'NNS'), 1),\n",
       " ((u'still', 'RB'), 1),\n",
       " ((u'tests', 'VBZ'), 1),\n",
       " ((u'repress', 'VB'), 1),\n",
       " ((u'met', 'VBD'), 1),\n",
       " ((u'connect', 'VB'), 1),\n",
       " ((u'city', 'NN'), 1),\n",
       " ((u'lost', 'VBN'), 1),\n",
       " ((u'active', 'JJ'), 1),\n",
       " ((u'uhh', 'JJ'), 1),\n",
       " ((u'e-board', 'NN'), 1),\n",
       " ((u'start', 'VBP'), 1),\n",
       " ((u'Uhh', 'NNP'), 1),\n",
       " ((u'depends', 'VBZ'), 1),\n",
       " ((u'happens', 'VBZ'), 1),\n",
       " ((u'myth', 'NN'), 1),\n",
       " ((u'least', 'JJS'), 1),\n",
       " ((u'meaning', 'NN'), 1),\n",
       " ((u'acknowledge', 'VB'), 1),\n",
       " ((u'institutions', 'NNS'), 1),\n",
       " ((u'It\\u2019s', 'NNP'), 1),\n",
       " ((u'\\u201d', 'NNP'), 1),\n",
       " ((u'\\u201cAhh', 'UH'), 1),\n",
       " ((u'currently', 'RB'), 1),\n",
       " ((u'much', 'JJ'), 1),\n",
       " ((u'Well', 'RB'), 1),\n",
       " ((u'ideas', 'NNS'), 1),\n",
       " ((u'Especially', 'RB'), 1),\n",
       " ((u'effort', 'NN'), 1),\n",
       " ((u'ground', 'NN'), 1),\n",
       " ((u'dialogue', 'VBP'), 1),\n",
       " ((u'morning', 'NN'), 1),\n",
       " ((u'Why', 'WRB'), 1),\n",
       " ((u'wake', 'VBP'), 1),\n",
       " ((u'wow', 'NN'), 1),\n",
       " ((u'happening', 'VBG'), 1),\n",
       " ((u'rewarding', 'VBG'), 1),\n",
       " ((u'provide', 'VBP'), 1),\n",
       " ((u'sharing', 'VBG'), 1),\n",
       " ((u'general', 'JJ'), 1),\n",
       " ((u'share', 'NN'), 1),\n",
       " ((u'APA', 'NNP'), 1),\n",
       " ((u'sense', 'NN'), 1),\n",
       " ((u'as', 'RB'), 1),\n",
       " ((u'money', 'NN'), 1)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(q4).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmn = Counter(q4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cmn = {k: v for k, v in cmn.iteritems() if  v > 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cmn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References\n",
    "\n",
    "- Peter Norvig [Everything I Need to Know About NLP I learned from Sesame Street][a1]\n",
    "\n",
    "\n",
    "[a1]: http://nbviewer.jupyter.org/url/norvig.com/ipython/How%20to%20Do%20Things%20with%20Words.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
